提交第一个spark应用到集群中运行
```
bin/spark-submit --master spark://node-5:7077 --class org.apache.spark.examples.SparkPi --executor-memory 2048mb --total-executor-cores 12  examples/jars/spark-examples_2.11-2.2.0.jar 1000
```
参数说明：
 spark-submit  脚本
 
 --master  指定master
 
 --class   指定类
 
 注意参数要在jar包之前指定，这些参数都是sparksubmit传给spark的；最后跟jar包路径及jar包运行参数
 
 提交任务的过程：
 ![任务提交](https://github.com/lijingxiao/spark/raw/master/%E5%85%A5%E9%97%A8/spark任务执行过程简介.png)
 1. 启动master
2. worker通过rpc通信向master注册信息，ha集群中会将worker信息持久化到zk，worker定时向master发送心跳
3. 客户端启动driver进程（sparksubmit）提交任务，先向master申请资源
	master负责资源调度，即分配资源（也就是在哪些worker上启动excutor）
4. master与worker进行rpc通信，让worker启动executor，同时将分区的参数传递给worker
5. worker启动executor
6. executor与driver进行通信执行任务
	executor会主动联系driver（通过master -> worker -> executor知道driver在哪）
	真正的计算逻辑是在driver端，driver端生成task，通过网络将任务分发到excutor端执行
  
  
**spark中master，worker，driver，excutor都负责什么工作**

 * driver：提交任务，并下发计算任务
 * master：负责worker的管理，负责资源调度
 * worker：报活、启动和管理worker
 * executor：负责执行计算任务
 
 Yarn和Spark的StandAlone调度模式对比

 | Header Cell | Header Cell | Header Cell |
| ------------- | ------------- | ------------- |
|ResouceManager | Master |  管理子节点、资源调度、接收任务请求 |
|NodeManager | Worker | 管理当前节点，并管理子进程 |
| YarnChild | Executor | 运行真正的计算逻辑的（Task） |
| Client | SparkSubmit | （Client + ApplicaitonMaster）提交app，管理该任务的Executor|
|ApplicaitonMaster| |并将Task提交到（Executor）|
 
 
 
